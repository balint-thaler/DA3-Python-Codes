{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 13\n",
    "**CH11 Used cars with linear regression**\n",
    "\n",
    "using the used-cars dataset\n",
    "\n",
    "version 1.0 2023-12-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mizani.formatters import percent_format\n",
    "import os\n",
    "from plotnine import *\n",
    "import numpy as np\n",
    "import sys\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from stargazer import stargazer\n",
    "from statsmodels.tools.eval_measures import mse,rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current script and repository folder\n",
    "current_path = os.getcwd()\n",
    "repository_path = current_path.split('Ch13-a-framework-for-prediction')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add utils folder to sys path \n",
    "# Note: os.path.join() creates a string with the right syntax for defining a path for your operating sytem.\n",
    "sys.path.append(os.path.join(repository_path, 'utils'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data folder\n",
    "data_path = os.path.join(repository_path, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the prewritten helper functions\n",
    "from py_helper_functions import *"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# DATA IMPORT - FROM FILE\n",
    "data = pd.read_csv(os.path.join(data_path, 'used-cars_2cities_prep.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA IMPORT - FROM GITHUB\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/peterduronelly/DA3-Python-Codes/main/data/used-cars_2cities_prep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE DESIGN\n",
    "\n",
    "# Manage missing\n",
    "data[\"fuel\"] = data[\"fuel\"].fillna(\"Missing\")\n",
    "data[\"condition\"] = data[\"condition\"].fillna(\"Missing\")\n",
    "data[\"drive\"] = data[\"drive\"].fillna(\"Missing\")\n",
    "data[\"cylinders\"] = data[\"cylinders\"].fillna(\"Missing\")\n",
    "data[\"transmission\"] = data[\"transmission\"].fillna(\"Missing\")\n",
    "data[\"type\"] = data[\"type\"].fillna(\"Missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop hybrid models then drop column\n",
    "data = data[data.Hybrid == 0].drop(\n",
    "    [\"Hybrid\"], axis=1\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check frequency by fuel type\n",
    "freq = data.groupby(\"fuel\").agg(frequency=(\"type\", \"size\"))\n",
    "freq[\"percent\"] = round(freq[\"frequency\"] / sum(freq[\"frequency\"]) * 100, 3)\n",
    "freq[\"cumulative_percent\"] = np.cumsum(freq[\"percent\"])\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep gas-fuelled vehicles\n",
    "data = data[data.fuel == \"gas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check frequency by vehicle condition\n",
    "freq = data.groupby(\"condition\").agg(frequency=(\"type\", \"size\"))\n",
    "freq[\"percent\"] = round(freq[\"frequency\"] / sum(freq[\"frequency\"]) * 100, 3)\n",
    "freq[\"cumulative_percent\"] = np.cumsum(freq[\"percent\"])\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop vehicles in fair and new condition, trucks\n",
    "data = data[~data.condition.isin([\"new\", \"fair\"])]\n",
    "\n",
    "# drop unrealistic values for price and odometer reading\n",
    "data = data[(data.price >= 500) & (data.price <= 25000) & (data.odometer <= 100)]\n",
    "\n",
    "# drop if price is smaller than 1000 and condition is like new or age is less than 8\n",
    "data = data[\n",
    "    ~((data.price < 1000) & ((data.condition == \"like new\") | (data.age < 8)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check frequency by transmission\n",
    "freq = data.groupby(\"transmission\").agg(frequency=(\"type\", \"size\"))\n",
    "freq[\"percent\"] = round(freq[\"frequency\"] / sum(freq[\"frequency\"]) * 100, 3)\n",
    "freq[\"cumulative_percent\"] = np.cumsum(freq[\"percent\"])\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~(data.transmission == \"manual\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check frequency by transmission\n",
    "freq = data.groupby(\"type\").agg(frequency=(\"type\", \"size\"))\n",
    "freq[\"percent\"] = round(freq[\"frequency\"] / sum(freq[\"frequency\"]) * 100, 3)\n",
    "freq[\"cumulative_percent\"] = np.cumsum(freq[\"percent\"])\n",
    "freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop if truck\n",
    "data = data[~(data.type == \"truck\")]\n",
    "# drop pricestr\n",
    "data = data.drop([\"pricestr\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition\n",
    "data[\"cond_excellent\"] = np.where(data[\"condition\"] == \"excellent\", 1, 0)\n",
    "data[\"cond_good\"] = np.where(data[\"condition\"] == \"good\", 1, 0)\n",
    "data[\"cond_likenew\"] = np.where(data[\"condition\"] == \"like new\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cylinders\n",
    "data[\"cylind6\"] = np.where(data[\"cylinders\"] == \"6 cylinders\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cylinders.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cylind6.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age: quadratic, cubic\n",
    "data[\"agesq\"] = data[\"age\"] ** 2\n",
    "data[\"agecu\"] = data[\"age\"] ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odometer quadratic\n",
    "data[\"odometersq\"] = data[\"odometer\"] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area\n",
    "data.groupby(\"area\").agg(frequency=(\"price\", 'size'), mean=(\"price\", np.mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to calculate multiple aggregations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area\n",
    "data.groupby(\"area\").agg({'price': ['count', 'mean']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus only on Chicago\n",
    "data = data[data.area == \"chicago\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition\n",
    "data.groupby(\"condition\").agg(frequency=(\"price\", \"size\"), mean=(\"price\", np.mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive\n",
    "data.groupby(\"drive\").agg(frequency=(\"price\", \"size\"), mean=(\"price\", np.mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealer\n",
    "data.groupby(\"dealer\").agg(frequency=(\"price\", \"size\"), mean=(\"price\", np.mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data summary\n",
    "data[[\n",
    "    \"age\",\n",
    "    \"odometer\",\n",
    "    \"LE\",\n",
    "    \"XLE\",\n",
    "    \"SE\",\n",
    "    \"cond_likenew\",\n",
    "    \"cond_excellent\",\n",
    "    \"cond_good\",\n",
    "    \"cylind6\",\n",
    "    ]].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charts\n",
    "\n",
    "We are using multiple ways to plot certain charts in this notebook. Python's primary plotting library is `matplotlib`(https://matplotlib.org/), which is very straightforward to start with but can easily be overwhelming when it comes to intricacies. A good intro can be found [here](https://fritz.ai/introduction-to-matplotlib-data-visualization-in-python/). \n",
    "\n",
    "There are multiple other plotting tools and libraries, most of which are some sort of wrapper around `matplotlib`. `seaborn` is a library for [analytical and statistical graphics](https://seaborn.pydata.org/tutorial/introduction.html), but sometimes it is sufficient to use `Pandas` `plot()` method for quick and simple charts.\n",
    "\n",
    "`R`, one of the data science & analytics alternatives for Python, is famous for its `ggplot` package which has been implemented in Python under the name `plotnine`. The syntaxes for building plotnine charts are almost the same as in `ggplot`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For certain charts, we need to sort values by age\n",
    "\n",
    "data.sort_values(by = 'age', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using plotnine\n",
    "ggplot(data, aes(x=\"price\")) + geom_histogram(\n",
    "    aes(y=\"(stat(count))/sum(stat(count))\"),\n",
    "    binwidth=1000,\n",
    "    boundary=0,\n",
    "    color=\"white\",\n",
    "    fill=color[0],\n",
    "    size=0.25,\n",
    "    alpha=0.8,\n",
    "    show_legend=False,\n",
    "    na_rm=True,\n",
    ") + coord_cartesian(xlim=(0, 20000)) + labs(\n",
    "    x=\"Price (US dollars)\", y=\"Percent\"\n",
    ") + theme_bw() + expand_limits(\n",
    "    x=0.01, y=0.01\n",
    ") + scale_y_continuous(\n",
    "    expand=(0.01, 0.01), labels=percent_format()\n",
    ") + scale_x_continuous(\n",
    "    expand=(0.01, 0.01), breaks=seq(0, 20000, 2500)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pandas plot()\n",
    "# tedious to plot relative frequencies\n",
    "data.plot(\n",
    "    kind = 'hist', figsize = (10,6),\n",
    "    y = 'price', bins = range(0, data.price.max(), 1000),\n",
    "    xticks = range(0, data.price.max(), 2000),\n",
    "    rwidth = 0.9, legend = False, \n",
    "    xlabel = 'price in USD', title = 'Absolute frequency by prices')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative frequencies with matplotlib\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "fig = plt.figure(figsize = (10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.hist(data.price,range(0, data.price.max(), 1000), density = True, rwidth = 0.9, color = 'steelblue')\n",
    "ax.set_xticks(range(0, data.price.max(), 2000))\n",
    "ax.set_xlabel('price in USD')\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(xmax=0.001, decimals = 0))\n",
    "ax.set_title('Relative frequency of car prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data, aes(x=\"lnprice\")) + geom_histogram(\n",
    "    aes(y=\"(stat(count)) / sum(stat(count))\"),\n",
    "    binwidth=0.2,\n",
    "    boundary=0,\n",
    "    color=\"white\",\n",
    "    fill=color[0],\n",
    "    size=0.25,\n",
    "    alpha=0.8,\n",
    "    show_legend=False,\n",
    "    na_rm=True,\n",
    ") + coord_cartesian(xlim=(6, 10)) + labs(\n",
    "    x=\"ln(Price, US dollars)\", y=\"Percent\"\n",
    ") + expand_limits(\n",
    "    x=0.01, y=0.01\n",
    ") + scale_y_continuous(\n",
    "    expand=(0.01, 0.01), labels=percent_format()\n",
    ") + scale_x_continuous(\n",
    "    expand=(0.01, 0.01), breaks=seq(6, 10, 1)\n",
    ") + theme_bw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pandas plot()\n",
    "data.plot(\n",
    "    kind = 'hist', figsize = (10,6),\n",
    "    y = 'lnprice', \n",
    "    bins = 18,\n",
    "    rwidth = 0.9, legend = False, \n",
    "    xlabel = 'log price in USD', title = 'Frequency by log prices')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression analysis - lo(w)ess\n",
    "\n",
    "We start with *loess* using first `ggplot` then `seaborn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowess with ggplot\n",
    "ggplot(data, aes(x=\"age\", y=\"price\")) + geom_point(\n",
    "    color=color[0], size=1, alpha=0.8, show_legend=False, na_rm=True\n",
    ") + geom_smooth(method=\"loess\", se=False, colour=color[0], size=1, span=0.9) + labs(\n",
    "    x=\"Age (years)\", y=\"Price (US dollars)\"\n",
    ") + theme_bw() + expand_limits(\n",
    "    x=0.01, y=0.01\n",
    ") + scale_y_continuous(\n",
    "    expand=(0.01, 0.01), limits=(0, 20000), breaks=seq(0, 20000, 5000)\n",
    ") + scale_x_continuous(\n",
    "    expand=(0.01, 0.01), limits=(0, 30), breaks=seq(0, 30, 5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `seaborn` it’s recommended to use a Jupyter/IPython interface in [matplotlib mode](https://ipython.readthedocs.io/en/stable/interactive/plotting.html) using the `%matplotlib inline` magic command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(\n",
    "    data = data,\n",
    "    x = 'age', y = 'price', \n",
    "    marker= '.',\n",
    "    fit_reg= True, lowess= True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools: on of the most-known tools data scientists use for predictive analysis is `scikit-learn`. Here, however, we use the `statsmodels` library that allows users to explore data, estimate statistical models, and perform statistical tests. `Scikit-learn` is great for building all kinds of predictive machine learning models, including linear regression, but spends little effort on providing insights into the models themselves. That's why we turn to `statsmodels` instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 0: lowess on age\n",
    "\n",
    "Note: the result of a lo(w)ess regression depends on the tools used. The values calculated below will be different compared to those seen on the `seaborn` regplot output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowess = sm.nonparametric.lowess\n",
    "y_hat_lowess = lowess(data.price, data.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_lowess[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_lowess = [x[1] for x in y_hat_lowess]\n",
    "y_hat_lowess[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Model 1: Linear regression on age\n",
    "\n",
    "We are building models by adding more and more explanatory variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = smf.ols(\"price ~ age + agesq\", data=data).fit(cov_type=\"HC0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(reg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg1.get_robustcov_results(cov_type='HC1').summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1.bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:   \n",
    "BIC = $n*ln(SSE/n)+k*ln(n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: We are expanding the base models by adding new explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = smf.ols(\"price ~ age + agesq + odometer\", data=data).fit(cov_type=\"HC0\")\n",
    "reg3 = smf.ols(\n",
    "    \"price ~ age + agesq + odometer + odometersq + LE + cond_excellent + cond_good + dealer\",\n",
    "    data=data,\n",
    ").fit(cov_type=\"HC0\")\n",
    "reg4 = smf.ols(\n",
    "    \"price ~ age + agesq + odometer + odometersq + LE + XLE + SE + cond_likenew + cond_excellent + cond_good + cylind6 + dealer\",\n",
    "    data=data,\n",
    ").fit(cov_type=\"HC0\")\n",
    "reg5 = smf.ols(\n",
    "    \"price ~ age + agesq + odometer + odometersq + LE * age + XLE * age + SE * age + cond_likenew * age + cond_excellent * age + cond_good * age + cylind6 * age + odometer * age + dealer * age\",\n",
    "    data=data,\n",
    ").fit(cov_type=\"HC0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [reg1, reg2, reg3, reg4, reg5]\n",
    "robustcov_results=[]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    result=model.get_robustcov_results(cov_type='HC1').summary()\n",
    "    robustcov_results.append(result)\n",
    "    print()\n",
    "    print(f'Regression: reg{i+1}')\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stargazer.Stargazer([reg1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data, aes(x=\"age\")) + geom_smooth(\n",
    "    aes(y=\"price\"),colour=color[0],linetype=\"dashed\", method=\"loess\", se=False, size=1\n",
    ") + geom_line(aes(y=\"reg1.predict()\"), colour=color[1], size=1) + labs(\n",
    "    x=\"Age (years)\", y=\"Price (US dollars)\"\n",
    ") + scale_color_manual(\n",
    "    name=\"\", values=(color[0], color[1]), labels=(\"Lowess in age\", \"Quadratic in age\")\n",
    ") + theme_bw() + scale_x_continuous(\n",
    "    limits=(0, 30), breaks=seq(0, 30, 5)\n",
    ") + scale_y_continuous(\n",
    "    limits=(0, 20000), breaks=seq(0, 20000, 5000)\n",
    ") + theme(\n",
    "    legend_position=(20, 20),\n",
    "    legend_direction=\"horizontal\",\n",
    "    legend_background=element_blank(),\n",
    "    legend_box_background=element_rect(color=\"white\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data.age, reg1.predict(), color = 'steelblue', linestyle = '-')\n",
    "plt.plot(data.age, y_hat_lowess, color = 'k', linestyle = \"--\")\n",
    "plt.legend(labels = ['regression 1', \"statsmodel's lowess\"])\n",
    "plt.title(\"Regression: model 1 vs statsmodel's lowess\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic = [round(x.bic, 2) for x in [reg1,reg2,reg3,reg4,reg5]]\n",
    "sg = stargazer.Stargazer([reg1,reg2,reg3,reg4,reg5])\n",
    "sg.add_line('BIC', bic, location=stargazer.LineLocation.FOOTER_BOTTOM)\n",
    "sg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to tailor-make `Stargazer` output see [here](https://github.com/StatsReporting/stargazer/blob/master/examples.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: Linear Regression with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k = KFold(n_splits=4, shuffle=False, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in k.split(data):\n",
    "    print(train_index, '\\n', '\\n', test_index, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross validate OLS with combining sklearn k-fold cross validation and statsmodels ols formula\n",
    "\n",
    "\n",
    "def cv_reg(formula, data, kfold, robustse=None):\n",
    "    regression_list = []\n",
    "    predicts_on_test = []\n",
    "    rsquared = []\n",
    "    rmse_list = []\n",
    "\n",
    "    # Calculating OLS for each fold\n",
    "\n",
    "    for train_index, test_index in k.split(data):\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        data_train, data_test = data.iloc[train_index, :], data.iloc[test_index, :]\n",
    "        if robustse is None:\n",
    "            model = smf.ols(formula, data=data_train).fit()\n",
    "        else:\n",
    "            model = smf.ols(formula, data=data_train).fit(cov_type=robustse)\n",
    "        regression_list += [model]\n",
    "        predicts_on_test += [model.predict(data_test)]\n",
    "        rsquared += [model.rsquared]\n",
    "        rmse_list += [rmse(data_train[formula.split(\"~\")[0]], model.predict())]\n",
    "\n",
    "    return {\n",
    "        \"regressions\": regression_list,\n",
    "        \"test_predict\": predicts_on_test,\n",
    "        \"r2\": rsquared,\n",
    "        \"rmse\": rmse_list,\n",
    "    }\n",
    "\n",
    "\n",
    "def summarize_cv(cvlist, stat=\"rmse\"):\n",
    "    result = pd.DataFrame(\n",
    "        {\"Model\" + str(x + 1): cvlist[x][stat] for x in range(len(cv_list))}\n",
    "    )\n",
    "    result[\"Resample\"] = [\"Fold\" + str(x + 1) for x in range(len(cvlist[0][\"rmse\"]))]\n",
    "    result = result.set_index(\"Resample\")\n",
    "    result = pd.concat([result, pd.DataFrame(result.mean(), columns=[\"Average\"]).T])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = cv_reg(\"price~age+agesq\", data, k, \"HC0\")\n",
    "cv2 = cv_reg(\"price~age+agesq+odometer\", data, k, \"HC0\")\n",
    "cv3 = cv_reg(\n",
    "    \"price~age+agesq+ odometer + odometersq + LE + cond_excellent + cond_good + dealer\",\n",
    "    data,\n",
    "    k,\n",
    "    \"HC0\",\n",
    ")\n",
    "cv4 = cv_reg(\n",
    "    \"price~age+agesq+ odometer + odometersq + LE + XLE + SE + cond_likenew + cond_excellent + cond_good + cylind6 + dealer\",\n",
    "    data,\n",
    "    k,\n",
    "    \"HC0\",\n",
    ")\n",
    "cv5 = cv_reg(\n",
    "    \"price~age+agesq + odometer + odometersq + LE*age + XLE*age + SE*age + cond_likenew*age + cond_excellent*age + cond_good*age + cylind6*age + odometer*age + dealer*age\",\n",
    "    data,\n",
    "    k,\n",
    "    \"HC0\",\n",
    ")\n",
    "cv_list = [cv1, cv2, cv3, cv4, cv5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_cv(cv_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[\n",
    "    [\n",
    "        \"age\",\n",
    "        \"agesq\",\n",
    "        \"odometer\",\n",
    "        \"odometersq\",\n",
    "        \"SE\",\n",
    "        \"LE\",\n",
    "        \"XLE\",\n",
    "        \"cond_likenew\",\n",
    "        \"cond_excellent\",\n",
    "        \"cond_good\",\n",
    "        \"dealer\",\n",
    "        \"price\",\n",
    "        \"cylind6\"\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.DataFrame(pd.Series({\n",
    "    \"age\":10,\n",
    "    \"agesq\":10**2,\n",
    "    \"odometer\":12,\n",
    "    \"odometersq\":12**2,\n",
    "    \"SE\":0,\n",
    "    \"LE\":1,\n",
    "    \"XLE\":0,\n",
    "    \"cond_likenew\":0,\n",
    "    \"cond_excellent\":1,\n",
    "    \"cond_good\":0,\n",
    "    \"dealer\":0,\n",
    "    \"price\":np.nan,\n",
    "    \"cylind6\":0\n",
    "})).T\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning off scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1.resid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=reg1.get_prediction(new).summary_frame()\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(reg3.fittedvalues-data.price).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2=reg3.get_prediction(new).summary_frame()\n",
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get model3 rmse\n",
    "rmse(reg3.fittedvalues,data.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \" \": [\"Predicted\", \"PI_low(95%)\", \"PI_high(95%)\"],\n",
    "        \"Model1\": p1[[\"mean\", \"obs_ci_lower\", \"obs_ci_upper\"]].values.tolist()[0],\n",
    "        \"Model3\": p2[[\"mean\", \"obs_ci_lower\", \"obs_ci_upper\"]].values.tolist()[0],\n",
    "    }\n",
    ").set_index(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of predictions and PI 80% version\n",
    "p1=reg1.get_prediction(new).summary_frame(alpha=0.2)\n",
    "p2=reg3.get_prediction(new).summary_frame(alpha=0.2)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \" \": [\"Predicted\", \"PI_low(80%)\", \"PI_high(80%)\"],\n",
    "        \"Model1\": p1[[\"mean\", \"obs_ci_lower\", \"obs_ci_upper\"]].values.tolist()[0],\n",
    "        \"Model3\": p2[[\"mean\", \"obs_ci_lower\", \"obs_ci_upper\"]].values.tolist()[0],\n",
    "    }\n",
    ").set_index(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
